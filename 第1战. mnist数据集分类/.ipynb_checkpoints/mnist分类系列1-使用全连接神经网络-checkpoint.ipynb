{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist字体识别\n",
    "### 第二篇：使用全连接神经网络实现mnist分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在keras中，常用的有两种构建模型的方式，即：  \n",
    "\n",
    "- 序贯模型：将网络定义为一个序列化的组成，类似于堆栈或队列，把不同的预定义模型按照线性管道叠加放到一起；\n",
    "- 函数化模型：使用keras的函数api，可以构建更复杂的模型。  \n",
    "\n",
    "我们将使用序贯模型来实现mnist数据集的分类。\n",
    "\n",
    "---\n",
    "第一步：导入模块；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/python3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后定义一些需要使用的数据；可以暂时不用理会这些变量的含义；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH = 5\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASS = 10\n",
    "OPTIMIZER = SGD()\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RESHAPED_SIZE = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据并标准化；这里暂时使用keras提供的类库；\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "# 这里的RESHAPED_SIZE表示目标大小；即将28*28的图像转化为784的向量；\n",
    "x_train = x_train.reshape(x_train.shape[0], RESHAPED_SIZE).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0],RESHAPED_SIZE).astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# 将模型标签转化为one-hot向量；例如3表示为[0.,0.,0.,1.,0.,0.,0.,0.,0.,0.]\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASS)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步，定义模型的结构，在这里我们使用一个简单的多层感知机的结构    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 第一层，有128个神经单元；\n",
    "model.add(Dense(128, input_shape=(RESHAPED_SIZE,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 第二层，有128个神经单元；\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 输出层，10个神经单元；\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# summary输出网络结构；\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是网络的编译和训练；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译网络，从而交给keras后端执行；\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complie函数的参数有以下几个需要注意的：\n",
    "\n",
    "- 优化器， 这是训练模型时用于更新权重的特定算法，如sgd、adma。\n",
    "- 目标函数， 也就是损失函数；\n",
    "- 评估指标，用于评估模型，常见的有3种：accuracy（准确率）、precision（查准率）、recall（查全率）。\n",
    "一旦模型编译好，就可以使用fit函数进行训练了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1295 - acc: 0.9639 - val_loss: 0.1422 - val_acc: 0.9593\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1270 - acc: 0.9640 - val_loss: 0.1403 - val_acc: 0.9599\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1247 - acc: 0.9649 - val_loss: 0.1388 - val_acc: 0.9606\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1224 - acc: 0.9652 - val_loss: 0.1372 - val_acc: 0.9605\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1202 - acc: 0.9664 - val_loss: 0.1361 - val_acc: 0.9608\n"
     ]
    }
   ],
   "source": [
    "# 模型的训练和优化；\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本例子中使用的fit的参数含义如下：\n",
    "\n",
    "- batch_size : 每次训练和梯度更新块的大小；\n",
    "- epochs: 迭代次数;这里为了显示方便，只训练5代；\n",
    "- verbose: 表示在训练过程中的输出情况，0表示不显示数据，1表示显示进度条，2表示只显示一个数据;\n",
    "- validation_split : 验证数据的使用比例；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在已经训练好了整个模型，在验证集上准确率为96.8%，最后在测试集上测试观察其准确率；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 42us/step\n",
      "Test score: 0.1310454538155347\n",
      "Test accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到我们的模型在测试集上最终结果为96%，然而，我们还有更好的模型和训练方法。\n",
    "\n",
    "下一篇将介绍以下内容：\n",
    "- **使用卷积神经网络模型来优化mnist分类模型；**\n",
    "- **使用mnist图像来进行训练；**\n",
    "- **模型的保存和使用；**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
