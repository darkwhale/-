{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist字体识别\n",
    "### 第三篇：使用卷积神经网络实现mnist分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望通过mnist数据集完成更多的东西，在很多的教程或资料中，一般都直接使用官方提供的mnist数据包来直接进行读取与测试。对于初学者来说，可能在做了实验之后也不太明白自己究竟做了什么，尤其对于一个新的分类任务，当我们只有一堆数据集的时候，往往无从下手。因此，本篇尝试直接使用mnist图像来进行训练和测试。\n",
    "\n",
    "---\n",
    "首先我们观察之前创建的数据集，一共有10个文件夹，每个文件夹下对应一类图像。我们开始的第一步就是需要读取这些图像，并载入标签，也就是要手工实现keras的mnist.load_data()函数.  \n",
    "**另外，在读取数据之前，我们先从图像集中剪切一部分图像出来，用作最后的预测，例如我从10个文件夹中分别抽取10张图片。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_image_label(dataset = \"dataset\"):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for image_dir in os.listdir(dataset):\n",
    "        for image_file in os.listdir(os.path.join(dataset, image_dir)):\n",
    "            image = cv2.imread(os.path.join(dataset,image_dir,image_file), 0)\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = image / 255.\n",
    "            label = int(image_dir)\n",
    "            \n",
    "            image_list.append(image)\n",
    "            label_list.append(label)\n",
    "            \n",
    "    x = np.array(image_list)\n",
    "    y = np.array(label_list)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义了一个get_image_label函数，该函数可以读取dataset文件夹下的文件，返回图像内容和标签。  \n",
    "\n",
    "第二步。我们可以开始定义网络模型了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/python3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend\n",
    "\n",
    "\n",
    "# lenet-5网络模型；\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=5, padding=\"same\",input_shape=(28,28,1)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Flatten层用于从卷积层到全连接层的过渡；\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码将定义经典的lenet-5 CNN结构。  \n",
    "\n",
    "第三步，准备读入数据，开始训练。  \n",
    "\n",
    "*tips:除了我们事先剪切出来的一小部分用于预测的图片，我们的get_image_label函数将返回所有图片的内容和标签。而在模型评估时需要用到不参与训练的数据进行测试，我们将使用一个强大的划分训练集测试集的工具：train_test_split()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = get_image_label()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1428)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以输出查看一下每个变量的纬度，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59937, 28, 28, 1) (9986, 28, 28, 1) (59937, 10) (9986, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来就是训练和评估模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# 编译网络，从而交给keras后端执行；\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47949 samples, validate on 11988 samples\n",
      "Epoch 1/5\n",
      "47949/47949 [==============================] - 107s 2ms/step - loss: 0.1873 - acc: 0.9430 - val_loss: 0.0744 - val_acc: 0.9773\n",
      "Epoch 2/5\n",
      "47949/47949 [==============================] - 103s 2ms/step - loss: 0.0486 - acc: 0.9845 - val_loss: 0.0426 - val_acc: 0.9865\n",
      "Epoch 3/5\n",
      "47949/47949 [==============================] - 104s 2ms/step - loss: 0.0343 - acc: 0.9892 - val_loss: 0.0345 - val_acc: 0.9892\n",
      "Epoch 4/5\n",
      "47949/47949 [==============================] - 104s 2ms/step - loss: 0.0250 - acc: 0.9918 - val_loss: 0.0325 - val_acc: 0.9897\n",
      "Epoch 5/5\n",
      "47949/47949 [==============================] - 104s 2ms/step - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0400 - val_acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "# 模型的训练和优化；\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=5, \n",
    "                    verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9986/9986 [==============================] - 7s 700us/step\n",
      "Test score: 0.04202176826189928\n",
      "Test accuracy: 0.9880833166433006\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型；\n",
    "model.save(\"mnist_cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型保存后会在目录下生存一个model_cnn.h5的文件，保留了训练好的权重。  \n",
    "我们新建一个模型，并对图像进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = create_model()\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时我们先直接预测一下图像类别，有如下几幅图像：\n",
    "\n",
    "<figure class=\"third\">\n",
    "    <img src=\"0.bmp\">\n",
    "    <img src=\"1.bmp\">\n",
    "    <img src=\"2.bmp\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n",
      "[7]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "# 预处理图像；\n",
    "def pre_process(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image.astype(\"float32\")\n",
    "\n",
    "print(new_model.predict_classes(pre_process(\"0.bmp\")))\n",
    "print(new_model.predict_classes(pre_process(\"1.bmp\")))\n",
    "print(new_model.predict_classes(pre_process(\"2.bmp\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们载入训练好的模型，再次测试观察其准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# 调用load_weights载入模型；\n",
    "new_model.load_weights(\"mnist_cnn.h5\")\n",
    "\n",
    "print(new_model.predict_classes(pre_process(\"0.bmp\")))\n",
    "print(new_model.predict_classes(pre_process(\"1.bmp\")))\n",
    "print(new_model.predict_classes(pre_process(\"2.bmp\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，测试结果正确，可自己多测试几幅图像。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
